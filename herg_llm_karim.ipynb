{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0fc9b99-2c6c-47a2-933d-37adad598f2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T13:29:14.190939Z",
     "iopub.status.busy": "2024-05-08T13:29:14.190060Z",
     "iopub.status.idle": "2024-05-08T13:29:14.751320Z",
     "shell.execute_reply": "2024-05-08T13:29:14.750205Z",
     "shell.execute_reply.started": "2024-05-08T13:29:14.190908Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Ensure the src directory is accessible\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7275e-a9fc-44b5-82a4-964b2c6f0f12",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660f19b0-4801-49df-a0b6-42caa57c82f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T13:29:21.318209Z",
     "iopub.status.busy": "2024-05-08T13:29:21.317742Z",
     "iopub.status.idle": "2024-05-08T13:29:28.744500Z",
     "shell.execute_reply": "2024-05-08T13:29:28.743623Z",
     "shell.execute_reply.started": "2024-05-08T13:29:21.318193Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "100%|██████████| 13445/13445 [00:05<00:00, 2307.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are       Drug_ID                                               Drug  Y\n",
      "0        8640  O=C1NCCN1CC[N+]1CCC(c2cn(C3CCCCC3)c3ccc(Cl)cc2...  0\n",
      "1       11377  O=C(Cc1ccc(-n2cnnn2)cc1)N1CCN(CCc2ccc3nonc3c2)CC1  1\n",
      "2        1461  NC(=O)c1ncc(N[C@@H]2CCCC[C@@H]2N)cc1Nc1cccc(C(...  1\n",
      "3        6646  Cc1cc(C)nc(Nc2cc(N[C@@H]3CCCC[C@@H]3N)cnc2C(N)...  1\n",
      "4         379  COc1cc(C)nc(Nc2cc(N[C@@H]3CCCC[C@@H]3N)cnc2C(N...  1\n",
      "...       ...                                                ... ..\n",
      "9406     5238  CC(C)(C)c1cc(NC(=O)n2ccc3cc(Oc4ncnc5c4CCNC5)cc...  1\n",
      "9407     6201  Cc1ccc2c(C3CCN(CCc4c(C)ccc5c4ccc(=O)n5C)CC3)cc...  1\n",
      "9408    11725  CCOC(=O)C1=C(CN2CCOCC2)NC(c2nccs2)=NC1c1ccc(F)...  1\n",
      "9409    12714  CCCCCCOC(=O)NC(=N)c1ccc(NCc2nc3cc(C(=O)N(CCC(=...  1\n",
      "9410    13134  Cn1c(CNc2ccc(C(=N)N)cc2)nc2cc(C(=O)N(CCC(=O)O)...  0\n",
      "\n",
      "[9411 rows x 3 columns] training samples,       Drug_ID                                               Drug  Y\n",
      "0         536        O=C(c1ccccc1C(F)(F)F)N(CC1CCCC1)[C@H]1CCNC1  0\n",
      "1        8140               CC(C)c1ccccc1C(=O)N(CC1CCCC1)C1CCNC1  1\n",
      "2        4261            O=C(c1ccccc1C(F)(F)F)N(CC1CCCC1)C1CCNC1  0\n",
      "3       10980           CC(C)c1ccccc1C(=O)N(CC1CCCC1)[C@H]1CCNC1  1\n",
      "4        8505  COc1ccc(C2(c3cccc(-c4cncnc4)c3)N=C(N)n3nc(C)cc...  1\n",
      "...       ...                                                ... ..\n",
      "1339     3585      CN1CCOCC1c1nc(C(=O)NCc2ccc(F)cc2)c(O)c(=O)n1C  0\n",
      "1340    13026  CO[C@@H](C(=O)N1Cc2[nH]nc(NC(=O)c3ccc(N4CCN(C)...  0\n",
      "1341      186  O=C1OCc2ccc(CCN3CCN(C(=O)Cc4ccc(-n5cnnn5)cc4)C...  0\n",
      "1342     3952           c1ccc(CN2CCN(Cc3nnc(-c4ccccc4)o3)CC2)cc1  0\n",
      "1343    10314  COc1ccc(CNC(=O)C2(c3ccccc3)CCN(c3cc(N)ccn3)CC2...  1\n",
      "\n",
      "[1344 rows x 3 columns] validation samples, and       Drug_ID                                               Drug  Y\n",
      "0        7417  CC(C)c1noc(-c2nnc3n2CCN(C(=O)c2ccc(F)cc2)[C@@H...  1\n",
      "1        3967  CCc1noc(-c2nnc3n2CCN(C(=O)c2ccc(F)cc2)[C@@H]3C)n1  0\n",
      "2       13387  CC(C)(C)Cn1c(N)nc2ccc(-c3nc(C(C)(C)C)[nH]c3-c3...  0\n",
      "3       10258  CC(C)(C)C1CCC2(CC1)CCN(c1ccc(OC(F)(F)F)cc1)C(=...  1\n",
      "4        5612  CCN(CC)c1ccc2cc(C(=O)NCCCCN3CCC(Nc4nc5ccccc5n4...  1\n",
      "...       ...                                                ... ..\n",
      "2685    10596    COCCN(C)Cc1csc(-c2cn(CC3CCOCC3)c3c(Cl)cccc23)n1  1\n",
      "2686    12520  CC(C)N(CCO)Cc1csc(-c2cn(CC3CCOCC3)c3c(Cl)cccc2...  1\n",
      "2687     2924  CC(C)N(CCO)Cc1nc(-c2cn(CC3CCOCC3)c3c(Cl)cccc23...  1\n",
      "2688     1138      CCN(CC)Cc1csc(-c2cn(CC3CCOCC3)c3c(F)cccc23)n1  1\n",
      "2689    12342  COC(=O)C(CCC(=O)N1CCN(c2ccccc2OC)CC1)(c1ccc(Br...  0\n",
      "\n",
      "[2690 rows x 3 columns] test samples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tdc.single_pred import Tox\n",
    "karim_data = Tox(name='hERG_Karim')\n",
    "data_split = karim_data.get_split(method='scaffold', seed=42)\n",
    "print(f\"There are {data_split['train']} training samples, {data_split['valid']} validation samples, and {data_split['test']} test samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a3be9-2573-4941-b103-dcca6391831a",
   "metadata": {},
   "source": [
    "# LLM based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3231b18-9a66-4528-8962-c38ba898007f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T13:29:28.811480Z",
     "iopub.status.busy": "2024-05-08T13:29:28.811312Z",
     "iopub.status.idle": "2024-05-08T13:29:31.284879Z",
     "shell.execute_reply": "2024-05-08T13:29:31.283385Z",
     "shell.execute_reply.started": "2024-05-08T13:29:28.811465Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, RobertaConfig, RobertaForSequenceClassification\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Define a custom dataset class\n",
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, smiles, labels, tokenizer, max_length=128):\n",
    "        self.smiles = smiles\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smile = self.smiles[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoded = self.tokenizer(smile, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        encoded_input = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "        return encoded_input, torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    \n",
    "# get pretrained tokenizer\n",
    "local_tokenizer_path = './huggingface/PubChem10M_SMILES_BPE_450k'  # Path where tokenizer files are stored\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_tokenizer_path) \n",
    "# if online: tokenizer = AutoTokenizer.from_pretrained(seyonec/PubChem10M_SMILES_BPE_450k) \n",
    "\n",
    "\n",
    "# Load existing configuration and modify it\n",
    "config_path = './huggingface/ChemBERTa-zinc-base-v1/config.json'\n",
    "model_config = RobertaConfig.from_pretrained(config_path)\n",
    "model_config.vocab_size = 7924  # Updating the vocab size\n",
    "model_config.num_labels = 1  # Ensure this is set for binary classification\n",
    "\n",
    "\n",
    "# Reinitialize the model with updated configuration\n",
    "model = RobertaForSequenceClassification(config=model_config)\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "train_smiles = data_split['train']['Drug'].tolist()\n",
    "train_labels = data_split['train']['Y'].tolist()\n",
    "valid_smiles = data_split['valid']['Drug'].tolist()\n",
    "valid_labels = data_split['valid']['Y'].tolist()\n",
    "\n",
    "train_dataset = SMILESDataset(train_smiles, train_labels, tokenizer)\n",
    "valid_dataset = SMILESDataset(valid_smiles, valid_labels, tokenizer)\n",
    "\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "# Training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device).unsqueeze(1)\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7616a80a-78d9-4925-afb1-a1126fb5c0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T13:34:08.350894Z",
     "iopub.status.busy": "2024-05-08T13:34:08.350475Z",
     "iopub.status.idle": "2024-05-08T13:34:09.650196Z",
     "shell.execute_reply": "2024-05-08T13:34:09.649656Z",
     "shell.execute_reply.started": "2024-05-08T13:34:08.350872Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from evaluate import eval\n",
    "\n",
    "def eval_model(model, data_loader, device, criterion, verbose=False):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    real_values = []\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            loss = criterion(outputs.logits, labels.to(device).unsqueeze(1))\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.sigmoid(outputs.logits)\n",
    "            predictions.extend(preds.flatten().tolist())\n",
    "            real_values.extend(labels.tolist())\n",
    "    \n",
    "    return {\n",
    "        'loss': total_loss,\n",
    "        'metrics': eval(real_values, predictions, verbose=verbose),\n",
    "    }\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f964a87-2610-40aa-b34d-8949e17de1d9",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-05-08T13:34:09.696071Z",
     "iopub.status.busy": "2024-05-08T13:34:09.695614Z",
     "iopub.status.idle": "2024-05-08T14:04:41.703795Z",
     "shell.execute_reply": "2024-05-08T14:04:41.702184Z",
     "shell.execute_reply.started": "2024-05-08T13:34:09.696053Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.6769, Validation Loss: 55.2452\n",
      "Epoch 1, Train Loss: 0.6444, Validation Loss: 54.9094\n",
      "Epoch 2, Train Loss: 0.6150, Validation Loss: 53.6050\n",
      "Epoch 3, Train Loss: 0.5939, Validation Loss: 61.0028\n",
      "Epoch 4, Train Loss: 0.5675, Validation Loss: 55.9971\n",
      "Epoch 5, Train Loss: 0.5487, Validation Loss: 53.7522\n",
      "Epoch 6, Train Loss: 0.5470, Validation Loss: 52.8785\n",
      "Epoch 7, Train Loss: 0.5469, Validation Loss: 51.1362\n",
      "Epoch 8, Train Loss: 0.5355, Validation Loss: 54.6660\n",
      "Epoch 9, Train Loss: 0.5111, Validation Loss: 57.4103\n",
      "Epoch 10, Train Loss: 0.5364, Validation Loss: 62.2459\n",
      "Epoch 11, Train Loss: 0.5082, Validation Loss: 55.8135\n",
      "Epoch 12, Train Loss: 0.4747, Validation Loss: 59.5490\n",
      "Epoch 13, Train Loss: 0.5094, Validation Loss: 59.9614\n",
      "Epoch 14, Train Loss: 0.6262, Validation Loss: 54.9900\n",
      "Epoch 15, Train Loss: 0.5655, Validation Loss: 55.0103\n",
      "Epoch 16, Train Loss: 0.5271, Validation Loss: 58.8801\n",
      "Epoch 17, Train Loss: 0.4968, Validation Loss: 54.9245\n",
      "Epoch 18, Train Loss: 0.4792, Validation Loss: 54.8912\n",
      "Epoch 19, Train Loss: 0.4814, Validation Loss: 54.4523\n",
      "Epoch 20, Train Loss: 0.4734, Validation Loss: 60.6065\n",
      "Epoch 21, Train Loss: 0.4750, Validation Loss: 54.5255\n",
      "Epoch 22, Train Loss: 0.5549, Validation Loss: 57.5272\n",
      "Epoch 23, Train Loss: 0.5722, Validation Loss: 56.1887\n",
      "Epoch 24, Train Loss: 0.5400, Validation Loss: 52.9728\n",
      "Epoch 25, Train Loss: 0.5127, Validation Loss: 56.1947\n",
      "Epoch 26, Train Loss: 0.5108, Validation Loss: 54.0029\n",
      "Epoch 27, Train Loss: 0.5255, Validation Loss: 56.7170\n",
      "Epoch 28, Train Loss: 0.5336, Validation Loss: 58.4857\n",
      "Epoch 29, Train Loss: 0.5359, Validation Loss: 56.1867\n",
      "Epoch 30, Train Loss: 0.5003, Validation Loss: 55.5678\n",
      "Epoch 31, Train Loss: 0.4842, Validation Loss: 57.9149\n",
      "Epoch 32, Train Loss: 0.4707, Validation Loss: 58.2436\n",
      "Epoch 33, Train Loss: 0.4637, Validation Loss: 56.2664\n",
      "Epoch 34, Train Loss: 0.4563, Validation Loss: 53.7472\n",
      "Epoch 35, Train Loss: 0.4454, Validation Loss: 58.1903\n",
      "Epoch 36, Train Loss: 0.4337, Validation Loss: 60.0906\n",
      "Epoch 37, Train Loss: 0.4477, Validation Loss: 61.6982\n",
      "Epoch 38, Train Loss: 0.4358, Validation Loss: 61.9123\n",
      "Epoch 39, Train Loss: 0.5200, Validation Loss: 52.4151\n",
      "Epoch 40, Train Loss: 0.5231, Validation Loss: 53.6775\n",
      "Epoch 41, Train Loss: 0.5271, Validation Loss: 55.6369\n",
      "Epoch 42, Train Loss: 0.5373, Validation Loss: 53.4231\n",
      "Epoch 43, Train Loss: 0.5152, Validation Loss: 53.4937\n",
      "Epoch 44, Train Loss: 0.5194, Validation Loss: 54.1297\n",
      "Epoch 45, Train Loss: 0.5370, Validation Loss: 54.8106\n",
      "Epoch 46, Train Loss: 0.5174, Validation Loss: 57.6466\n",
      "Epoch 47, Train Loss: 0.4970, Validation Loss: 59.4510\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m total_valid_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 8\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     valid_result \u001b[38;5;241m=\u001b[39m eval_model(model, valid_loader, device, criterion)\n\u001b[1;32m     10\u001b[0m     total_train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[3], line 74\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, device, criterion)\u001b[0m\n\u001b[1;32m     72\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     73\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[1;32m     75\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {key: val\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     76\u001b[0m     labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[3], line 25\u001b[0m, in \u001b[0;36mSMILESDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     23\u001b[0m smile \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msmiles[idx]\n\u001b[1;32m     24\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabels[idx]\n\u001b[0;32m---> 25\u001b[0m encoded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmax_length\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m encoded_input \u001b[38;5;241m=\u001b[39m {key: val\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m encoded\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_input, torch\u001b[38;5;241m.\u001b[39mtensor(label, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2858\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2856\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   2857\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 2858\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2860\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:2964\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m   2945\u001b[0m         batch_text_or_text_pairs\u001b[38;5;241m=\u001b[39mbatch_text_or_text_pairs,\n\u001b[1;32m   2946\u001b[0m         add_special_tokens\u001b[38;5;241m=\u001b[39madd_special_tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2961\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2962\u001b[0m     )\n\u001b[1;32m   2963\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2964\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2965\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2967\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2968\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2974\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2976\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2977\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2978\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2979\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2980\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2981\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2982\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2983\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:3037\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3027\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3028\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3029\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3030\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3034\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3035\u001b[0m )\n\u001b[0;32m-> 3037\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3038\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3039\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3040\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3041\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3042\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3043\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3045\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3055\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:234\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    232\u001b[0m )\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py:576\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_encode_plus\u001b[39m(\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    556\u001b[0m     text: Union[TextInput, PreTokenizedInput],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    574\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchEncoding:\n\u001b[1;32m    575\u001b[0m     batched_input \u001b[38;5;241m=\u001b[39m [(text, text_pair)] \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;28;01melse\u001b[39;00m [text]\n\u001b[0;32m--> 576\u001b[0m     batched_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatched_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;66;03m# Return tensor is None, then we can remove the leading batch axis\u001b[39;00m\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;66;03m# Overflowing tokens are returned as a batch of output so we keep them in this case\u001b[39;00m\n\u001b[1;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_tensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_overflowing_tokens:\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/transformers/models/roberta/tokenization_roberta_fast.py:224\u001b[0m, in \u001b[0;36mRobertaTokenizerFast._batch_encode_plus\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m is_split_into_words \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_split_into_words\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_prefix_space \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_split_into_words, (\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou need to instantiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with add_prefix_space=True \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto use it with pretokenized inputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    222\u001b[0m )\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/transformers/tokenization_utils_fast.py:552\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m input_ids \u001b[38;5;129;01min\u001b[39;00m sanitized_tokens[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eventual_warn_about_too_long_sequence(input_ids, max_length, verbose)\n\u001b[0;32m--> 552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatchEncoding\u001b[49m\u001b[43m(\u001b[49m\u001b[43msanitized_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msanitized_encodings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:224\u001b[0m, in \u001b[0;36mBatchEncoding.__init__\u001b[0;34m(self, data, encoding, tensor_type, prepend_batch_axis, n_sequences)\u001b[0m\n\u001b[1;32m    220\u001b[0m     n_sequences \u001b[38;5;241m=\u001b[39m encoding[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mn_sequences\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_sequences \u001b[38;5;241m=\u001b[39m n_sequences\n\u001b[0;32m--> 224\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_tensors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepend_batch_axis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:759\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors\u001b[0;34m(self, tensor_type, prepend_batch_axis)\u001b[0m\n\u001b[1;32m    756\u001b[0m     value \u001b[38;5;241m=\u001b[39m [value]\n\u001b[1;32m    758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor(value):\n\u001b[0;32m--> 759\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mas_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    761\u001b[0m     \u001b[38;5;66;03m# Removing this for now in favor of controlling the shape with `prepend_batch_axis`\u001b[39;00m\n\u001b[1;32m    762\u001b[0m     \u001b[38;5;66;03m# # at-least2d\u001b[39;00m\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;66;03m# if tensor.ndim > 2:\u001b[39;00m\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor.squeeze(0)\u001b[39;00m\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;66;03m# elif tensor.ndim < 2:\u001b[39;00m\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;66;03m#     tensor = tensor[None, :]\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[38;5;28mself\u001b[39m[key] \u001b[38;5;241m=\u001b[39m tensor\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:721\u001b[0m, in \u001b[0;36mBatchEncoding.convert_to_tensors.<locals>.as_tensor\u001b[0;34m(value, dtype)\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value[\u001b[38;5;241m0\u001b[39m], np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mtensor(np\u001b[38;5;241m.\u001b[39marray(value))\n\u001b[0;32m--> 721\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpoint_dir = './src/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "num_epochs = 100\n",
    "total_train_losses = []\n",
    "total_valid_losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device, criterion)\n",
    "    valid_result = eval_model(model, valid_loader, device, criterion)\n",
    "    total_train_losses.append(train_loss)\n",
    "    total_valid_losses.append(valid_result['loss'])\n",
    "    print(f\"Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation Loss: {valid_result['loss']:.4f}\")\n",
    "\n",
    "    # Save the checkpoint every two epochs\n",
    "    if epoch % 2 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "        }, checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b303e67c-9f35-49f9-9a5a-1af4fbfc4624",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T14:05:37.294526Z",
     "iopub.status.busy": "2024-05-08T14:05:37.294074Z",
     "iopub.status.idle": "2024-05-08T14:05:37.512515Z",
     "shell.execute_reply": "2024-05-08T14:05:37.512058Z",
     "shell.execute_reply.started": "2024-05-08T14:05:37.294503Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Converting tensors to lists of scalars\n",
    "visual_train_losses = [x for x in total_train_losses]\n",
    "visual_valid_losses = [x for x in total_valid_losses]\n",
    "\n",
    "# Plotting the values\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(visual_train_losses, label='Training Loss')\n",
    "plt.plot(visual_valid_losses, label='Validation Los')\n",
    "plt.title('Training of Simple Neural Network')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a31615-de62-4544-90a9-e1e811deeb2c",
   "metadata": {},
   "source": [
    "# Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb8a9831-cc6d-440e-9f70-f747452a0282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-08T14:38:06.106876Z",
     "iopub.status.busy": "2024-05-08T14:38:06.106440Z",
     "iopub.status.idle": "2024-05-08T14:38:10.165816Z",
     "shell.execute_reply": "2024-05-08T14:38:10.165221Z",
     "shell.execute_reply.started": "2024-05-08T14:38:06.106856Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 34 with loss 0.4563\n",
      "Accuracy: 0.7159851301115242\n",
      "ROC AUC Score: 0.7914378882966284\n",
      "Precision: 0.6969909027291813\n",
      "Recall: 0.7505651846269782\n",
      "F1 Score: 0.7227866473149492\n",
      "Matthews Correlation Coefficient: 0.4336914538773981\n",
      "Specificity (Negative Prediction Accuracy): 0.6823184152604549\n"
     ]
    }
   ],
   "source": [
    "def load_checkpoint(model, optimizer, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f'Loaded checkpoint from epoch {epoch} with loss {loss:.4f}')\n",
    "    return model, optimizer, epoch, loss\n",
    "\n",
    "\n",
    "# select the best model:\n",
    "epoch_n = 34\n",
    "checkpoint_path = f'./src/checkpoints/checkpoint_epoch_{epoch_n}.pt'\n",
    "\n",
    "model, optimizer, start_epoch, train_loss = load_checkpoint(model, optimizer, checkpoint_path)\n",
    "\n",
    "test_smiles = data_split['test']['Drug'].tolist()\n",
    "test_labels = data_split['test']['Y'].tolist()\n",
    "test_dataset = SMILESDataset(test_smiles, test_labels, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "test_performance = eval_model(model, test_loader, device, criterion, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e7ef4-1cb1-4caa-93ca-f1189d62f0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "herg",
   "language": "python",
   "name": "herg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
