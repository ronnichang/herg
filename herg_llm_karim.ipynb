{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0fc9b99-2c6c-47a2-933d-37adad598f2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:30:11.672262Z",
     "iopub.status.busy": "2024-05-01T18:30:11.671985Z",
     "iopub.status.idle": "2024-05-01T18:30:11.718705Z",
     "shell.execute_reply": "2024-05-01T18:30:11.718146Z",
     "shell.execute_reply.started": "2024-05-01T18:30:11.672243Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Import necessary libraries\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Ensure the src directory is accessible\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b7275e-a9fc-44b5-82a4-964b2c6f0f12",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "660f19b0-4801-49df-a0b6-42caa57c82f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:14:00.200354Z",
     "iopub.status.busy": "2024-05-01T18:14:00.200013Z",
     "iopub.status.idle": "2024-05-01T18:14:07.324112Z",
     "shell.execute_reply": "2024-05-01T18:14:07.323304Z",
     "shell.execute_reply.started": "2024-05-01T18:14:00.200334Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "100%|██████████| 13445/13445 [00:05<00:00, 2300.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and split successfully.\n",
      "Train data samples: 9411\n",
      "Validation data samples: 1344\n",
      "Test data samples: 2690\n"
     ]
    }
   ],
   "source": [
    "from get_data import get_data\n",
    "data_split = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb749a25-ac83-44cd-8e54-aac9def4d97c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:14:11.605981Z",
     "iopub.status.busy": "2024-05-01T18:14:11.605659Z",
     "iopub.status.idle": "2024-05-01T18:14:11.645169Z",
     "shell.execute_reply": "2024-05-01T18:14:11.644293Z",
     "shell.execute_reply.started": "2024-05-01T18:14:11.605963Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'valid', 'test'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_split.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151a3be9-2573-4941-b103-dcca6391831a",
   "metadata": {},
   "source": [
    "# LLM based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3231b18-9a66-4528-8962-c38ba898007f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:30:25.200646Z",
     "iopub.status.busy": "2024-05-01T18:30:25.200339Z",
     "iopub.status.idle": "2024-05-01T18:30:25.855187Z",
     "shell.execute_reply": "2024-05-01T18:30:25.853826Z",
     "shell.execute_reply.started": "2024-05-01T18:30:25.200628Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, RobertaConfig, RobertaForSequenceClassification\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "# Define a custom dataset class\n",
    "class SMILESDataset(Dataset):\n",
    "    def __init__(self, smiles, labels, tokenizer, max_length=128):\n",
    "        self.smiles = smiles\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.smiles)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        smile = self.smiles[idx]\n",
    "        label = self.labels[idx]\n",
    "        encoded = self.tokenizer(smile, return_tensors='pt', max_length=self.max_length, padding='max_length', truncation=True)\n",
    "        encoded_input = {key: val.squeeze(0) for key, val in encoded.items()}\n",
    "        return encoded_input, torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "    \n",
    "# get pretrained tokenizer\n",
    "local_tokenizer_path = './huggingface/PubChem10M_SMILES_BPE_450k'  # Path where tokenizer files are stored\n",
    "tokenizer = AutoTokenizer.from_pretrained(local_tokenizer_path) \n",
    "# if online: tokenizer = AutoTokenizer.from_pretrained(seyonec/PubChem10M_SMILES_BPE_450k) \n",
    "\n",
    "\n",
    "# Load existing configuration and modify it\n",
    "config_path = './huggingface/ChemBERTa-zinc-base-v1/config.json'\n",
    "model_config = RobertaConfig.from_pretrained(config_path)\n",
    "model_config.vocab_size = 7924  # Updating the vocab size\n",
    "model_config.num_labels = 1  # Ensure this is set for binary classification\n",
    "\n",
    "\n",
    "# Reinitialize the model with updated configuration\n",
    "model = RobertaForSequenceClassification(config=model_config)\n",
    "\n",
    "\n",
    "# Prepare data\n",
    "train_smiles = data_split['train']['Drug'].tolist()\n",
    "train_labels = data_split['train']['Y'].tolist()\n",
    "valid_smiles = data_split['valid']['Drug'].tolist()\n",
    "valid_labels = data_split['valid']['Y'].tolist()\n",
    "\n",
    "train_dataset = SMILESDataset(train_smiles, train_labels, tokenizer)\n",
    "valid_dataset = SMILESDataset(valid_smiles, valid_labels, tokenizer)\n",
    "\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "# Training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "def train_epoch(model, data_loader, optimizer, device, criterion):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for inputs, labels in data_loader:\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        labels = labels.to(device).unsqueeze(1)\n",
    "        outputs = model(**inputs)\n",
    "        loss = criterion(outputs.logits, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7616a80a-78d9-4925-afb1-a1126fb5c0a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T20:07:16.559754Z",
     "iopub.status.busy": "2024-05-01T20:07:16.559432Z",
     "iopub.status.idle": "2024-05-01T20:07:16.602885Z",
     "shell.execute_reply": "2024-05-01T20:07:16.602464Z",
     "shell.execute_reply.started": "2024-05-01T20:07:16.559736Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from evaluate import eval\n",
    "\n",
    "def eval_model(model, data_loader, device, verbose=False):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    real_values = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            preds = torch.sigmoid(outputs.logits)\n",
    "            predictions.extend(preds.flatten().tolist())\n",
    "            real_values.extend(labels.tolist())\n",
    "    \n",
    "    return eval(real_values, predictions, verbose=verbose)  \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f964a87-2610-40aa-b34d-8949e17de1d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T18:30:33.677502Z",
     "iopub.status.busy": "2024-05-01T18:30:33.677247Z",
     "iopub.status.idle": "2024-05-01T19:04:14.547487Z",
     "shell.execute_reply": "2024-05-01T19:04:14.546638Z",
     "shell.execute_reply.started": "2024-05-01T18:30:33.677484Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train Loss: 0.7045, Validation AUC: 0.6686\n",
      "Epoch 1, Train Loss: 0.6587, Validation AUC: 0.6814\n",
      "Epoch 2, Train Loss: 0.6275, Validation AUC: 0.6957\n",
      "Epoch 3, Train Loss: 0.6023, Validation AUC: 0.6974\n",
      "Epoch 4, Train Loss: 0.5713, Validation AUC: 0.7160\n",
      "Epoch 5, Train Loss: 0.5515, Validation AUC: 0.7141\n",
      "Epoch 6, Train Loss: 0.5574, Validation AUC: 0.7082\n",
      "Epoch 7, Train Loss: 0.5515, Validation AUC: 0.7004\n",
      "Epoch 8, Train Loss: 0.5215, Validation AUC: 0.7176\n",
      "Epoch 9, Train Loss: 0.4969, Validation AUC: 0.6972\n",
      "Epoch 10, Train Loss: 0.4867, Validation AUC: 0.7060\n",
      "Epoch 11, Train Loss: 0.4885, Validation AUC: 0.7150\n",
      "Epoch 12, Train Loss: 0.4569, Validation AUC: 0.7243\n",
      "Epoch 13, Train Loss: 0.4369, Validation AUC: 0.7203\n",
      "Epoch 14, Train Loss: 0.4313, Validation AUC: 0.7155\n",
      "Epoch 15, Train Loss: 0.4649, Validation AUC: 0.6933\n",
      "Epoch 16, Train Loss: 0.4396, Validation AUC: 0.6959\n",
      "Epoch 17, Train Loss: 0.5053, Validation AUC: 0.6674\n",
      "Epoch 18, Train Loss: 0.5241, Validation AUC: 0.6733\n",
      "Epoch 19, Train Loss: 0.5361, Validation AUC: 0.6587\n",
      "Epoch 20, Train Loss: 0.4983, Validation AUC: 0.7154\n",
      "Epoch 21, Train Loss: 0.4833, Validation AUC: 0.7204\n",
      "Epoch 22, Train Loss: 0.4981, Validation AUC: 0.7287\n",
      "Epoch 23, Train Loss: 0.4480, Validation AUC: 0.7106\n",
      "Epoch 24, Train Loss: 0.4753, Validation AUC: 0.6952\n",
      "Epoch 25, Train Loss: 0.5423, Validation AUC: 0.5384\n",
      "Epoch 26, Train Loss: 0.6065, Validation AUC: 0.6534\n",
      "Epoch 27, Train Loss: 0.5116, Validation AUC: 0.6520\n",
      "Epoch 28, Train Loss: 0.5134, Validation AUC: 0.6498\n",
      "Epoch 29, Train Loss: 0.5336, Validation AUC: 0.4718\n",
      "Epoch 30, Train Loss: 0.6896, Validation AUC: 0.5759\n",
      "Epoch 31, Train Loss: 0.6951, Validation AUC: 0.5758\n",
      "Epoch 32, Train Loss: 0.6897, Validation AUC: 0.6706\n",
      "Epoch 33, Train Loss: 0.5712, Validation AUC: 0.6485\n",
      "Epoch 34, Train Loss: 0.6538, Validation AUC: 0.5982\n",
      "Epoch 35, Train Loss: 0.6824, Validation AUC: 0.5325\n",
      "Epoch 36, Train Loss: 0.6790, Validation AUC: 0.5699\n",
      "Epoch 37, Train Loss: 0.6170, Validation AUC: 0.5864\n",
      "Epoch 38, Train Loss: 0.6176, Validation AUC: 0.6153\n",
      "Epoch 39, Train Loss: 0.6391, Validation AUC: 0.5980\n",
      "Epoch 40, Train Loss: 0.6634, Validation AUC: 0.5136\n",
      "Epoch 41, Train Loss: 0.6746, Validation AUC: 0.5116\n",
      "Epoch 42, Train Loss: 0.6776, Validation AUC: 0.5161\n",
      "Epoch 43, Train Loss: 0.6760, Validation AUC: 0.5137\n",
      "Epoch 44, Train Loss: 0.6753, Validation AUC: 0.5146\n",
      "Epoch 45, Train Loss: 0.6733, Validation AUC: 0.5139\n",
      "Epoch 46, Train Loss: 0.6730, Validation AUC: 0.5104\n",
      "Epoch 47, Train Loss: 0.6734, Validation AUC: 0.5236\n",
      "Epoch 48, Train Loss: 0.6711, Validation AUC: 0.5160\n",
      "Epoch 49, Train Loss: 0.6709, Validation AUC: 0.5160\n",
      "Epoch 50, Train Loss: 0.6704, Validation AUC: 0.5167\n",
      "Epoch 51, Train Loss: 0.6712, Validation AUC: 0.5160\n",
      "Epoch 52, Train Loss: 0.6725, Validation AUC: 0.5153\n",
      "Epoch 53, Train Loss: 0.6706, Validation AUC: 0.5153\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m----> 6\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     valid_auc \u001b[38;5;241m=\u001b[39m eval_model(model, valid_loader, device)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation AUC: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalid_auc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 83\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, optimizer, device, criterion)\u001b[0m\n\u001b[1;32m     81\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     82\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 83\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_loader)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "checkpoint_dir = './src/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "epoch_start = 0\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, device, criterion)\n",
    "    valid_auc = eval_model(model, valid_loader, device)\n",
    "    print(f'Epoch {epoch}, Train Loss: {train_loss:.4f}, Validation AUC: {valid_auc:.4f}')\n",
    "\n",
    "    # Save the checkpoint every two epochs\n",
    "    if epoch % 2 == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch}.pt')\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "        }, checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a31615-de62-4544-90a9-e1e811deeb2c",
   "metadata": {},
   "source": [
    "# Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bb8a9831-cc6d-440e-9f70-f747452a0282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T19:38:20.199512Z",
     "iopub.status.busy": "2024-05-01T19:38:20.199206Z",
     "iopub.status.idle": "2024-05-01T19:38:21.830223Z",
     "shell.execute_reply": "2024-05-01T19:38:21.829764Z",
     "shell.execute_reply.started": "2024-05-01T19:38:20.199494Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded checkpoint from epoch 22 with loss 0.4981\n"
     ]
    }
   ],
   "source": [
    "def load_checkpoint(model, optimizer, checkpoint_path):\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    print(f'Loaded checkpoint from epoch {epoch} with loss {loss:.4f}')\n",
    "    return model, optimizer, epoch, loss\n",
    "\n",
    "# select the best model:\n",
    "epoch_n = 22\n",
    "checkpoint_path = f'./src/checkpoints/checkpoint_epoch_{epoch_n}.pt'\n",
    "model, optimizer, start_epoch, train_loss = load_checkpoint(model, optimizer, checkpoint_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b02d250f-9b7e-42aa-a71b-99c2cb266fe9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T21:18:28.411759Z",
     "iopub.status.busy": "2024-05-01T21:18:28.411281Z",
     "iopub.status.idle": "2024-05-01T21:18:32.813584Z",
     "shell.execute_reply": "2024-05-01T21:18:32.813137Z",
     "shell.execute_reply.started": "2024-05-01T21:18:28.411739Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7100371747211895\n",
      "ROC AUC Score: 0.7865136360293936\n",
      "Precision: 0.7118512780790085\n",
      "Recall: 0.6925395629238885\n",
      "F1 Score: 0.7020626432391139\n",
      "Matthews Correlation Coefficient: 0.4199131877537424\n",
      "Specificity (Negative Prediction Accuracy): 0.727072633895818\n"
     ]
    }
   ],
   "source": [
    "test_smiles = data_split['test']['Drug'].tolist()\n",
    "test_labels = data_split['test']['Y'].tolist()\n",
    "test_dataset = SMILESDataset(test_smiles, test_labels, tokenizer)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "test_performance = eval_model(model, test_loader, device, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70e7ef4-1cb1-4caa-93ca-f1189d62f0c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "herg",
   "language": "python",
   "name": "herg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
