{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0fc9b99-2c6c-47a2-933d-37adad598f2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T20:29:52.284614Z",
     "iopub.status.busy": "2024-05-01T20:29:52.284358Z",
     "iopub.status.idle": "2024-05-01T20:29:52.326128Z",
     "shell.execute_reply": "2024-05-01T20:29:52.325729Z",
     "shell.execute_reply.started": "2024-05-01T20:29:52.284596Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# Import necessary libraries\n",
    "import sys\n",
    "from pathlib import Path\n",
    "# Ensure the src directory is accessible\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08a15c7-5bad-4ccc-a1cf-ecbbce188a9e",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b5c49c88-0141-411f-bd39-fdeabcc8bf4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T20:31:37.265826Z",
     "iopub.status.busy": "2024-05-01T20:31:37.265470Z",
     "iopub.status.idle": "2024-05-01T20:31:43.029728Z",
     "shell.execute_reply": "2024-05-01T20:31:43.029291Z",
     "shell.execute_reply.started": "2024-05-01T20:31:37.265808Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n",
      "Loading...\n",
      "Done!\n",
      "100%|██████████| 13445/13445 [00:05<00:00, 2362.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and split successfully.\n",
      "Train data samples: 9411\n",
      "Validation data samples: 1344\n",
      "Test data samples: 2690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from get_data import get_data\n",
    "data_split = get_data() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a26645-3a17-4256-9e77-0f42f6941d0a",
   "metadata": {},
   "source": [
    "# Featuring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e1299d07-75a8-4deb-86fe-d6d512739ba9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T20:31:55.199599Z",
     "iopub.status.busy": "2024-05-01T20:31:55.199372Z",
     "iopub.status.idle": "2024-05-01T20:31:55.232106Z",
     "shell.execute_reply": "2024-05-01T20:31:55.231625Z",
     "shell.execute_reply.started": "2024-05-01T20:31:55.199583Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from features import smiles_to_fp\n",
    "\n",
    "# Prepare the data\n",
    "def prepare_data(df):\n",
    "    df['features'] = df['Drug'].apply(lambda x: smiles_to_fp(x))\n",
    "    X = list(df['features'])\n",
    "    y = df['Y'].values\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd894a9-2595-4d06-b9a8-3a9ec8f8807d",
   "metadata": {},
   "source": [
    "# Prepare traing and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ff48bc4b-ae71-44fe-bbcf-65bdcf8a27de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T20:32:00.203058Z",
     "iopub.status.busy": "2024-05-01T20:32:00.202734Z",
     "iopub.status.idle": "2024-05-01T20:32:13.210927Z",
     "shell.execute_reply": "2024-05-01T20:32:13.209512Z",
     "shell.execute_reply.started": "2024-05-01T20:32:00.203040Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make features\n",
    "train_data = data_split['train']\n",
    "X_train, y_train = prepare_data(train_data)\n",
    "\n",
    "valid_data = data_split['valid']\n",
    "X_valid, y_valid = prepare_data(valid_data)\n",
    "\n",
    "test_data = data_split['test'] \n",
    "X_test, y_test = prepare_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31513ba9-1c74-43f4-ad39-86d401aa4f09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f46353df-a3ec-4a61-861d-f0a4f88491ac",
   "metadata": {},
   "source": [
    "# LTN first trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "51c03dae-9490-484c-998e-f2e1bb82c1c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-01T20:13:04.426493Z",
     "iopub.status.busy": "2024-05-01T20:13:04.426320Z",
     "iopub.status.idle": "2024-05-01T20:13:04.804086Z",
     "shell.execute_reply": "2024-05-01T20:13:04.803183Z",
     "shell.execute_reply.started": "2024-05-01T20:13:04.426477Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Using a target size (torch.Size([9411, 1, 1])) that is different to the input size (torch.Size([9411, 1])) is deprecated. Please ensure they have the same size.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Execute the training\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Set model to evaluation mode\u001b[39;00m\n\u001b[1;32m     51\u001b[0m nn_model\u001b[38;5;241m.\u001b[39meval()\n",
      "Cell \u001b[0;32mIn[33], line 40\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, X_train, y_train, optimizer, epochs)\u001b[0m\n\u001b[1;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     39\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(X_train)  \u001b[38;5;66;03m# Directly use the model\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBCELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     42\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/torch/nn/modules/loss.py:618\u001b[0m, in \u001b[0;36mBCELoss.forward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    617\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 618\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/herg/lib/python3.9/site-packages/torch/nn/functional.py:3118\u001b[0m, in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3116\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize():\n\u001b[0;32m-> 3118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3119\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a target size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) that is different to the input size (\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m) is deprecated. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3120\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure they have the same size.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(target\u001b[38;5;241m.\u001b[39msize(), \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m   3121\u001b[0m     )\n\u001b[1;32m   3123\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3124\u001b[0m     new_size \u001b[38;5;241m=\u001b[39m _infer_size(target\u001b[38;5;241m.\u001b[39msize(), weight\u001b[38;5;241m.\u001b[39msize())\n",
      "\u001b[0;31mValueError\u001b[0m: Using a target size (torch.Size([9411, 1, 1])) that is different to the input size (torch.Size([9411, 1])) is deprecated. Please ensure they have the same size."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class LTNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LTNModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(1024, 64),  # Assuming input features size of 1024\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),  # binary classification\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Instantiate the model\n",
    "model = LTNModel()\n",
    "\n",
    "# Prepare data\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Define and run the training function\n",
    "def train(model, X_train, y_train, optimizer, epochs=100):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)  # Directly use the model\n",
    "        loss = nn.BCELoss()(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Execute the training\n",
    "train(model, X_train_tensor, y_train_tensor, optimizer)\n",
    "\n",
    "\n",
    "# Set model to evaluation mode\n",
    "nn_model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_test_tensor)\n",
    "predictions = (outputs > 0.5).float()  # Threshold probabilities to classify as 1 or 0\n",
    "\n",
    "# Since you cannot use sklearn directly with tensors, you need to move data back to CPU and convert to numpy\n",
    "predictions = predictions.cpu().numpy()\n",
    "y_test_tensor = y_test_tensor.cpu().numpy()\n",
    "eval(y_test_tensor, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc1d58d-ed0e-41c6-9855-eb14c31d761d",
   "metadata": {},
   "source": [
    "# Logic Tensor Network (LTN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d007c8-73d4-40b3-8626-787f9fac70f8",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-24T14:31:18.386078Z",
     "iopub.status.idle": "2024-04-24T14:31:18.386308Z",
     "shell.execute_reply": "2024-04-24T14:31:18.386203Z",
     "shell.execute_reply.started": "2024-04-24T14:31:18.386194Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ltn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de3c1b7-5a04-4eea-a5ce-87da86c45e80",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-24T14:31:18.387066Z",
     "iopub.status.idle": "2024-04-24T14:31:18.387458Z",
     "shell.execute_reply": "2024-04-24T14:31:18.387360Z",
     "shell.execute_reply.started": "2024-04-24T14:31:18.387350Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LTNModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LTNModel, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(1024, 64),  # Assuming input features size of 1024\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),  # binary classification\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "        \n",
    "    \n",
    "# Instantiate model and predicate\n",
    "ltn_model = LTNModel()\n",
    "#predicate_toxic = ltn.Predicate(ltn_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03da0656-adf6-42a0-9bfa-20b473660e0a",
   "metadata": {},
   "source": [
    "# LTN: Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99664e3-6c4a-49ec-a85f-1baf3b04f316",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-24T14:31:18.387955Z",
     "iopub.status.idle": "2024-04-24T14:31:18.388291Z",
     "shell.execute_reply": "2024-04-24T14:31:18.388194Z",
     "shell.execute_reply.started": "2024-04-24T14:31:18.388185Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Rule: Structural similarity implies similar toxicity\n",
    "# Define a similarity measure (could be cosine similarity, Jaccard index, etc. for molecular fingerprints)\n",
    "def similarity(x, y):\n",
    "    return torch.cosine_similarity(x, y, dim=1)\n",
    "\n",
    "# Logical rule\n",
    "def rule_structural_similarity(data):\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data)):\n",
    "            # Enforce that similar compounds should have similar toxicity predictions\n",
    "            ltn.axiom((similarity(data[i], data[j]) > 0.8) >> (ltn.equivalence(predicate_toxic(data[i]), predicate_toxic(data[j]))))\n",
    "\n",
    "\n",
    "            \n",
    "def structure_similarity(data, epsilon=0.85):\n",
    "    # Assume a function that calculates pairwise similarity (e.g., cosine similarity)\n",
    "    similarities = torch.mm(data, data.t())  # This is a simplistic way to compute similarities\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data)):\n",
    "            # Adding similarity rule: similar structures imply similar toxicity levels\n",
    "            ltn.axiom((similarities[i, j] > epsilon) >> (ltn.equivalence(predicate_toxic(data[i]), predicate_toxic(data[j]))))\n",
    "\n",
    "# Dummy function for presence of specific substructures (you need actual implementation based on your data)\n",
    "def presence_of_toxic_substructures(data, indices_of_substructures):\n",
    "    for i in range(len(data)):\n",
    "        if any(data[i][idx] == 1 for idx in indices_of_substructures):\n",
    "            ltn.axiom(predicate_toxic(data[i]))            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fad4504-cebd-4c0e-8ef2-1ed5b12e35a4",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e39bb-d7e6-4195-9105-19985796fc33",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-24T14:31:18.388818Z",
     "iopub.status.idle": "2024-04-24T14:31:18.389200Z",
     "shell.execute_reply": "2024-04-24T14:31:18.389096Z",
     "shell.execute_reply.started": "2024-04-24T14:31:18.389087Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bde769c-a473-4a39-bfdd-4f9185978818",
   "metadata": {},
   "source": [
    "# LTN: Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc49351-1401-4633-82fb-f5eb1a7d3269",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-24T14:31:18.389678Z",
     "iopub.status.idle": "2024-04-24T14:31:18.389956Z",
     "shell.execute_reply": "2024-04-24T14:31:18.389860Z",
     "shell.execute_reply.started": "2024-04-24T14:31:18.389851Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ltn_optimizer = optim.Adam(ltn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Define a training function\n",
    "def ltn_train(predicate, X_train, y_train, optimizer, epochs=100):\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = predicate(X_train)  # Using the predicate directly\n",
    "        loss = nn.BCELoss()(outputs.tensor, y_train.tensor)  # Accessing the tensor from the LTN Tensor\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")\n",
    "            \n",
    "# Step 7: Run the training\n",
    "# Execute the training\n",
    "ltn_train(predicate_toxic, X_train_ltn, y_train_ltn, ltn_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7716641-377b-4355-91cf-ea41eb3ebada",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-04-24T14:31:18.390470Z",
     "iopub.status.idle": "2024-04-24T14:31:18.390668Z",
     "shell.execute_reply": "2024-04-24T14:31:18.390577Z",
     "shell.execute_reply.started": "2024-04-24T14:31:18.390568Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = predicate_toxic(X_test_term)\n",
    "    test_predictions = (test_outputs > 0.5).float()\n",
    "    accuracy = (test_predictions == y_test_term.tensor).float().mean()  # Compare against the tensor inside the term\n",
    "    print(f\"Test Accuracy: {accuracy.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325679b5-64b0-48dd-9cb8-a936077eec2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd5f63e-b5c4-4b8e-b89a-59fdce85cf3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07bc1ed-710d-4a36-bbb0-994907e2cc80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf42726-9466-4dc9-837b-822710256977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5eb506f-3f4c-43e0-8a43-430f6046eebe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2f0b27-6cf8-45de-98a9-64a8b90b2539",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "herg",
   "language": "python",
   "name": "herg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
